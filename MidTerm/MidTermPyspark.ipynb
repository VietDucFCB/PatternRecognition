{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498ab69-75b6-44cc-8bbf-213245b6bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, StringType, DoubleType\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, col\n",
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# Tạo SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EEG Data Processing with Fourier Transform\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf0f4d8-6a21-4f7b-a58d-bc87143c2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------+--------------------+\n",
      "|    subject|  state|channel|          raw_signal|\n",
      "+-----------+-------+-------+--------------------+\n",
      "|eeg_record1|focused|    AF3|[4440.00000000000...|\n",
      "|eeg_record1|focused|     F7|[4417.94871794871...|\n",
      "|eeg_record1|focused|     F3|[5390.76923076923...|\n",
      "|eeg_record1|focused|    FC5|[3833.84615384615...|\n",
      "|eeg_record1|focused|     T7|[4019.48717948718...|\n",
      "+-----------+-------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# Định nghĩa schema cho Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"subject\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"channel\", StringType(), True),\n",
    "    StructField(\"raw_signal\", ArrayType(DoubleType()), True)\n",
    "])\n",
    "\n",
    "# Hàm đọc file `.mat`\n",
    "def read_mat_file(file_path):\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    data = mat['o']['data'][0, 0]\n",
    "    samp_freq = mat['o']['sampFreq'][0, 0][0][0]\n",
    "    states = {\n",
    "        'focused': data[:samp_freq * 10 * 60, :],\n",
    "        'unfocused': data[samp_freq * 10 * 60:samp_freq * 20 * 60, :],\n",
    "        'drowsy': data[samp_freq * 30 * 60:, :]\n",
    "    }\n",
    "    return states\n",
    "\n",
    "# Tạo dữ liệu từ các file\n",
    "data_root = 'eeg_data'\n",
    "rows = []\n",
    "channel_map = {\n",
    "    'AF3': 3, 'F7': 4, 'F3': 5, 'FC5': 6, 'T7': 7, 'P7': 8,\n",
    "    'O1': 9, 'O2': 10, 'P8': 11, 'T8': 12, 'FC6': 13, 'F4': 14, 'F8': 15, 'AF4': 16\n",
    "}\n",
    "\n",
    "for mat_file in os.listdir(data_root):\n",
    "    if mat_file.endswith('.mat'):\n",
    "        states = read_mat_file(os.path.join(data_root, mat_file))\n",
    "        subject_id = mat_file.split('.')[0]\n",
    "        for state, eeg_data in states.items():\n",
    "            for channel_name, channel_idx in channel_map.items():\n",
    "                signal = eeg_data[:, channel_idx]\n",
    "                rows.append((subject_id, state, channel_name, signal.tolist()))\n",
    "\n",
    "# Chuyển dữ liệu thành Spark DataFrame\n",
    "df = spark.createDataFrame(rows, schema=schema)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0e60c-fab6-4ad4-9cb8-a53b7a7462b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fourier Features Extraction\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a640601-a4a2-4a46-b96f-168444116c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "\n",
    "@pandas_udf(StructType([\n",
    "    StructField(\"fft_mean\", DoubleType(), True),\n",
    "    StructField(\"fft_variance\", DoubleType(), True),\n",
    "    StructField(\"fft_kurtosis\", DoubleType(), True),\n",
    "    StructField(\"fft_skewness\", DoubleType(), True),\n",
    "    StructField(\"fft_max_frequency\", DoubleType(), True),\n",
    "    StructField(\"fft_power_spectrum\", DoubleType(), True)\n",
    "]), PandasUDFType.SCALAR)\n",
    "def extract_fourier_features_udf(signals):\n",
    "    results = []\n",
    "    sampling_rate = 128\n",
    "    for signal in signals:\n",
    "        if len(signal) == 0:\n",
    "            results.append([None] * 6)\n",
    "            continue\n",
    "        N = len(signal)\n",
    "        freq = fftfreq(N, d=1/sampling_rate)\n",
    "        fft_values = np.abs(fft(signal))\n",
    "\n",
    "        features = [\n",
    "            np.mean(fft_values),\n",
    "            np.var(fft_values),\n",
    "            kurtosis(fft_values),\n",
    "            skew(fft_values),\n",
    "            freq[np.argmax(fft_values)],\n",
    "            np.sum(fft_values**2) / N\n",
    "        ]\n",
    "        results.append(features)\n",
    "    return pd.DataFrame(results, columns=[\"fft_mean\", \"fft_variance\", \"fft_kurtosis\", \"fft_skewness\", \"fft_max_frequency\", \"fft_power_spectrum\"])\n",
    "\n",
    "df = df.withColumn(\"fourier_features\", extract_fourier_features_udf(col(\"raw_signal\")))\n",
    "df.select(\"subject\", \"state\", \"channel\", \"fourier_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1e66f-bc59-491c-ae1f-c902c769e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF tính các đặc trưng wavelet\n",
    "@pandas_udf(\"map<string,double>\", PandasUDFType.SCALAR)\n",
    "def extract_wavelet_features_udf(signals):\n",
    "    results = []\n",
    "    for signal in signals:\n",
    "        if len(signal) == 0:\n",
    "            results.append({})\n",
    "            continue\n",
    "        coeffs = pywt.wavedec(signal, 'db4', level=4)\n",
    "        features = {}\n",
    "        for i, coeff in enumerate(coeffs):\n",
    "            features[f'level_{i}_energy'] = np.sum(coeff**2)\n",
    "            features[f'level_{i}_mean'] = np.mean(coeff)\n",
    "            features[f'level_{i}_kurt'] = kurtosis(coeff)\n",
    "            features[f'level_{i}_skew'] = skew(coeff)\n",
    "        results.append(features)\n",
    "    return results\n",
    "\n",
    "# Thêm cột wavelet features\n",
    "df = df.withColumn(\"wavelet_features\", extract_wavelet_features_udf(col(\"raw_signal\")))\n",
    "df.select(\"subject\", \"state\", \"channel\", \"wavelet_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6ae6e-7658-4ee3-ad51-9458c7b03a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "def remove_outliers(df, col_name):\n",
    "    q1 = df.approxQuantile(col_name, [0.25], 0.01)[0]\n",
    "    q3 = df.approxQuantile(col_name, [0.75], 0.01)[0]\n",
    "    iqr = q3 - q1\n",
    "    lower_bound, upper_bound = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df.filter((col(col_name) >= lower_bound) & (col(col_name) <= upper_bound))\n",
    "\n",
    "# Áp dụng loại bỏ outliers\n",
    "columns_to_check = ['band_powers', 'wavelet_features']\n",
    "for col_name in columns_to_check:\n",
    "    df = remove_outliers(df, col_name)\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950ffb1-2ff4-4bbb-8f7e-eef3a7e95176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Chuyển đổi về Pandas DataFrame\n",
    "pandas_df = df.toPandas()\n",
    "\n",
    "# Vẽ histogram\n",
    "pandas_df['band_powers'].apply(pd.Series).hist(figsize=(10, 8))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
